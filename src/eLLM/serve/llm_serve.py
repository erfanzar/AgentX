from abc import abstractmethod

import gradio as gr
from ._theme import seafoam
from typing import List
from ..interactors.base import BaseInteract
from .configuration import SampleParams

CHAT_MODE = [
    "Instruction",
    "Chat"
]

js = """function () {
  gradioURL = window.location.href
  if (!gradioURL.endsWith("?__theme=dark")) {
    window.location.replace(gradioURL + "?__theme=dark");
  }
}"""


class LLMServe:
    """
    The `LLMServe` class is a Python class that represents a user's interaction with a language
    model. It has an `__init__` method that initializes the class with an `inference_session` object,
    `max_new_tokens`, and `max_length` parameters. The `inference_session` object is used to perform
    inference with the language model. The `max_new_tokens` parameter sets the maximum number of tokens that
    can be used in a single query, and the `max_length` parameter sets the maximum length of a sentence.
    """

    def __init__(
            self,
            interactor: BaseInteract,
            sample_config: SampleParams,
            use_prefix_for_interactor: bool = True,
    ):
        self.sample_config = sample_config
        self.interactor = interactor
        self.use_prefix_for_interactor = use_prefix_for_interactor

    @abstractmethod
    def sample(
            self,
            prompt: str,
            history: List[List[str]],
            system_prompt: str,
            mode: CHAT_MODE = CHAT_MODE[-1],
            max_length: int = 8192,
            max_new_tokens: int = 4096,
            temperature: float = 0.8,
            top_p: float = 0.9,
            top_k: int = 50
    ):
        """
        The sample function is the main entry point for a user to interact with the model.
        It takes in a prompt, which can be any string, and returns an iterator over
        strings that are generated by the model.
        The sample function also takes in some optional arguments:

        :param self: Refer to the current object
        :param prompt: str: Pass in the text that you want to generate a response for
        :param history: List[List[str]]: Keep track of the conversation history
        :param system_prompt: str: the model system prompt.
        :param mode: str: represent the mode that model inference be used in (e.g. chat or instruction)
        :param max_length: int: Maximum Length for model
        :param max_new_tokens: int: Limit the number of tokens in a response
        :param temperature: float: Control the randomness of the generated text
        :param top_p: float: Control the probability of sampling from the top k tokens
        :param top_k: int: Control the number of candidates that are considered for each token
        :return: A generator that yields the next token in the sequence
        """

    def chat_interface_components(self):
        """
        The function `chat_interface_components` creates the components for a chat interface, including
        a chat history, message box, buttons for submitting, stopping, and clearing the conversation,
        and sliders for advanced options.
        """
        with gr.Column("100%"):
            gr.Markdown(
                "# <h1><center style='color:white;'>Powered by "
                "[EasyDeL](https://github.com/erfanzar/EasyDel)</center></h1>",
            )
            history = gr.Chatbot(
                elem_id="EasyDel",
                label="EasyDel",
                container=True,
                height="65vh",
            )
            prompt = gr.Textbox(
                show_label=False, placeholder="Enter Your Prompt Here.", container=False
            )
            with gr.Row():
                submit = gr.Button(
                    value="Run",
                    variant="primary"
                )
                stop = gr.Button(
                    value="Stop"
                )
                clear = gr.Button(
                    value="Clear Conversation"
                )
            with gr.Accordion(open=False, label="Advanced Options"):
                system_prompt = gr.Textbox(
                    value="",
                    show_label=True,
                    label="system Prompt",
                    placeholder="system Prompt",
                    container=False
                )

                max_length = gr.Slider(
                    value=self.sample_config.max_length,
                    maximum=10000,
                    minimum=1,
                    label="Max Length",
                    step=1
                )

                max_new_tokens = gr.Slider(
                    value=self.sample_config.max_new_tokens,
                    maximum=10000,
                    minimum=1,
                    label="Max New Tokens",
                    step=1
                )
                temperature = gr.Slider(
                    value=self.sample_config.temperature,
                    maximum=1,
                    minimum=0.1,
                    label="Temperature",
                    step=0.01
                )
                top_p = gr.Slider(
                    value=self.sample_config.top_p,
                    maximum=1,
                    minimum=0.1,
                    label="Top P",
                    step=0.01
                )
                top_k = gr.Slider(
                    value=self.sample_config.top_k,
                    maximum=100,
                    minimum=1,
                    label="Top K",
                    step=1
                )
                mode = gr.Dropdown(
                    choices=CHAT_MODE,
                    value=self.sample_config.mode,
                    label="Mode",
                    multiselect=False
                )

        inputs = [
            prompt,
            history,
            system_prompt,
            mode,
            max_length,
            max_new_tokens,
            temperature,
            top_p,
            top_k
        ]

        clear.click(fn=lambda: [], outputs=[history])
        sub_event = submit.click(
            fn=self.sample, inputs=inputs, outputs=[prompt, history]
        )
        txt_event = prompt.submit(
            fn=self.sample, inputs=inputs, outputs=[prompt, history]
        )

        stop.click(fn=None, inputs=None, outputs=None,
                   cancels=[txt_event, sub_event])

    def build_chat_interface(self) -> gr.Blocks:
        """
        The build function is the main entry point for your app.
        It should return a single gr.Block instance that will be displayed in the browser.

        :param self: Make the class methods work with an instance of the class
        :return: A block, which is then queued
        """
        with gr.Blocks(
                theme=seafoam,
                title="Chat",
                css="footer {visibility: hidden}"
        ) as block:
            self.chat_interface_components()
        block.queue()
        return block

    def build_inference(self) -> gr.Blocks:
        """
        The function "build_inference" returns a gr.Blocks object that contains two tabs, one for model
        interface components and one for chat interface components.
        :return: a gr.Blocks object.
        """
        with gr.Blocks(
                theme=seafoam,
                css="footer {visibility: hidden}"
        ) as block:
            with gr.Tab("Chat"):
                self.chat_interface_components()
        return block

    def __repr__(self):

        """
        The __repr__ function is used to generate a string representation of an object.
        This function should return a string that can be parsed by the Python interpreter
        to recreate the object. The __repr__ function is called when you use print() on an
        object, or when you type its name in the REPL.

        :param self: Refer to the instance of the class
        :return: A string representation of the object
        """
        string = f"{self.__class__.__name__}(\n"
        for k, v in self.__dict__.items():
            if not k.startswith("_"):
                repr_src = f"\t{k} : " + v.__str__().replace("\n", "\n\t") + "\n"
                string += repr_src if len(repr_src) < 500 else f"\t{k} : " + f"{v.__class__.__name__}(...)" + "\n"
        return string + ")"

    def __str__(self):

        """
        The __str__ function is called when you use the print function or when str() is used.
        It should return a string representation of the object.

        :param self: Refer to the instance of the class
        :return: The object's string representation
        """
        return self.__repr__()
